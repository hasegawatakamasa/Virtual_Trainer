import Foundation
import Vision
import CoreML
import UIKit
import Combine

/// AI/MLãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹
@MainActor
class MLModelManager: ObservableObject {
    
    // MARK: - Published Properties
    @Published var isModelLoaded = false
    @Published var loadingError: AppError?
    @Published var lastInferenceTime: TimeInterval = 0.0
    @Published var lastDetectedPose: PoseKeypoints?
    
    // MARK: - Private Properties
    private var poseModel: VNCoreMLModel?
    private var formModel: MLModel?
    private let processingQueue = DispatchQueue(label: "ml.processing", qos: .userInitiated)
    
    // æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ç”¨ã®çŠ¶æ…‹ç®¡ç†
    private var mockExercisePhase: Double = 0.0  // 0.0ã€œ2Ï€ ã®ã‚µã‚¤ã‚¯ãƒ«
    private var mockPhaseSpeed: Double = 0.05    // ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®é€²è¡Œé€Ÿåº¦
    
    // MARK: - Initialization
    init() {
        loadModels()
    }
    
    // MARK: - Model Loading
    
    private func loadModels() {
        Task {
            await loadPoseModel()
            await loadFormModel()
            
            await MainActor.run {
                self.isModelLoaded = (self.poseModel != nil) && (self.formModel != nil)
                if self.isModelLoaded {
                    print("âœ… AIãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº† (YOLO11n-pose + GRU)")
                } else {
                    print("âš ï¸ AIãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - æ¨¡æ“¬ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™")
                    self.loadingError = AppError.modelLoadingFailed("ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                }
            }
        }
    }
    
    private func loadPoseModel() async {
        // ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿(.mlmodelc)ã¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸(.mlpackage)ã®ä¸¡æ–¹ã‚’ãƒã‚§ãƒƒã‚¯
        var modelURL: URL?
        
        // ã¾ãšã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™
        if let compiledURL = Bundle.main.url(forResource: "YOLO11nPose", withExtension: "mlmodelc") {
            modelURL = compiledURL
        }
        // æ¬¡ã«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™
        else if let packageURL = Bundle.main.url(forResource: "YOLO11nPose", withExtension: "mlpackage") {
            modelURL = packageURL
        }
        
        guard let modelURL = modelURL else {
            return
        }
        
        do {
            let mlModel = try MLModel(contentsOf: modelURL)
            self.poseModel = try VNCoreMLModel(for: mlModel)
        } catch {
            print("âŒ YOLO11nPoseãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: \(error)")
        }
    }
    
    private func loadFormModel() async {
        // ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿(.mlmodelc)ã¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸(.mlpackage)ã®ä¸¡æ–¹ã‚’ãƒã‚§ãƒƒã‚¯
        var modelURL: URL?
        
        // ã¾ãšã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™
        if let compiledURL = Bundle.main.url(forResource: "GRUFormClassifier", withExtension: "mlmodelc") {
            modelURL = compiledURL
        }
        // æ¬¡ã«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™
        else if let packageURL = Bundle.main.url(forResource: "GRUFormClassifier", withExtension: "mlpackage") {
            modelURL = packageURL
        }
        
        guard let modelURL = modelURL else {
            return
        }
        
        do {
            self.formModel = try MLModel(contentsOf: modelURL)
        } catch {
            print("âŒ GRUFormClassifierãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: \(error)")
        }
    }
    
    // MARK: - Pose Detection
    
    /// Vision ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ã£ãŸå§¿å‹¢æ¤œå‡º
    func detectPose(in pixelBuffer: CVPixelBuffer) async -> PoseKeypoints? {
        guard let poseModel = poseModel else {
            // ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯nilã‚’è¿”ã™ï¼ˆæ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ã¯ä½¿ã‚ãªã„ï¼‰
            return nil
        }
        
        return await withCheckedContinuation { continuation in
            let request = VNCoreMLRequest(model: poseModel) { request, error in
                if let error = error {
                    print("âŒ å§¿å‹¢æ¤œå‡ºã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)")
                    continuation.resume(returning: nil)
                    return
                }
                
                guard let observations = request.results as? [VNCoreMLFeatureValueObservation],
                      let firstObservation = observations.first,
                      let multiArray = firstObservation.featureValue.multiArrayValue else {
                    continuation.resume(returning: nil)
                    return
                }
                
                let keypoints = self.parseYOLOOutput(multiArray)
                
                // ãƒ¡ã‚¤ãƒ³ã‚¢ã‚¯ã‚¿ãƒ¼ã§Publishedãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’æ›´æ–°
                Task { @MainActor in
                    self.lastDetectedPose = keypoints
                }
                
                continuation.resume(returning: keypoints)
            }
            
            request.imageCropAndScaleOption = .scaleFill
            
            let handler = VNImageRequestHandler(cvPixelBuffer: pixelBuffer, options: [:])
            do {
                try handler.perform([request])
            } catch {
                print("âŒ Vision requestå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: \\(error)")
                continuation.resume(returning: nil)
            }
        }
    }
    
    private func parseYOLOOutput(_ multiArray: MLMultiArray) -> PoseKeypoints? {
        // YOLO11n-poseã®å‡ºåŠ›å½¢å¼: (1, 56, 8400)
        // 56 = 4 (bbox) + 1 (conf) + 51 (17 keypoints Ã— 3: x, y, visibility)
        
        guard multiArray.shape.count >= 3 else {
            print("âŒ äºˆæœŸã—ãªã„å‡ºåŠ›å½¢çŠ¶: \\(multiArray.shape)")
            return nil
        }
        
        let numDetections = multiArray.shape[2].intValue
        guard numDetections > 0 else { return nil }
        
        // æœ€ã‚‚ä¿¡é ¼åº¦ã®é«˜ã„æ¤œå‡ºã‚’é¸æŠ
        var bestConfidence: Float = 0.0
        var bestDetectionIndex = 0
        
        for i in 0..<numDetections {
            let confidence = multiArray[[0, 4, i] as [NSNumber]].floatValue
            if confidence > bestConfidence {
                bestConfidence = confidence
                bestDetectionIndex = i
            }
        }
        
        guard bestConfidence > 0.3 else { // æœ€å°ä¿¡é ¼åº¦ãƒã‚§ãƒƒã‚¯
            return nil
        }
        
        // ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡º
        var points: [CGPoint] = []
        var confidences: [Float] = []
        
        for keypointIndex in 0..<17 {
            let xIndex = 5 + keypointIndex * 3
            let yIndex = 5 + keypointIndex * 3 + 1
            let confIndex = 5 + keypointIndex * 3 + 2
            
            let x = multiArray[[0, xIndex, bestDetectionIndex] as [NSNumber]].floatValue
            let y = multiArray[[0, yIndex, bestDetectionIndex] as [NSNumber]].floatValue
            let conf = multiArray[[0, confIndex, bestDetectionIndex] as [NSNumber]].floatValue
            
            points.append(CGPoint(x: Double(x), y: Double(y)))
            confidences.append(conf)
        }
        
        return PoseKeypoints(points: points, confidence: confidences)
    }
    
    // MARK: - Form Classification
    
    /// GRUãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸãƒ•ã‚©ãƒ¼ãƒ åˆ†é¡
    func classifyForm(features: [[Float]]) async -> FormClassification {
        guard let formModel = formModel,
              features.count >= 10 else {
            // ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ããªã„å ´åˆã‚„ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯æ¨¡æ“¬çµæœã‚’è¿”ã™
            return generateMockFormClassification()
        }
        
        return await withCheckedContinuation { continuation in
            processingQueue.async {
                do {
                    // å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆ10ãƒ•ãƒ¬ãƒ¼ãƒ  Ã— 12ç‰¹å¾´é‡ï¼‰
                    let inputArray = try MLMultiArray(shape: [1, 10, 12], dataType: .float32)
                    
                    for (frameIndex, frame) in features.prefix(10).enumerated() {
                        for (featureIndex, value) in frame.prefix(12).enumerated() {
                            inputArray[[0, frameIndex, featureIndex] as [NSNumber]] = NSNumber(value: value)
                        }
                    }
                    
                    let input = try MLDictionaryFeatureProvider(dictionary: ["features": MLFeatureValue(multiArray: inputArray)])
                    let prediction = try formModel.prediction(from: input)
                    
                    guard let outputArray = prediction.featureValue(for: "prediction")?.multiArrayValue else {
                        continuation.resume(returning: .ready)
                        return
                    }
                    
                    let confidence = outputArray[0].floatValue
                    let classification: FormClassification
                    
                    if confidence < 0.3 {
                        classification = .normal
                    } else if confidence < 0.7 {
                        classification = .elbowError
                    } else {
                        classification = .tooFast
                    }
                    
                    continuation.resume(returning: classification)
                    
                } catch {
                    print("âŒ ãƒ•ã‚©ãƒ¼ãƒ åˆ†é¡ã‚¨ãƒ©ãƒ¼: \\(error)")
                    continuation.resume(returning: .ready)
                }
            }
        }
    }
    
    // MARK: - Mock Data Generation
    
    private func generateMockPoseKeypoints() -> PoseKeypoints {
        let points = (0..<17).map { index -> CGPoint in
            switch index {
            case 5, 6: // è‚©
                return CGPoint(x: 200 + Double(index - 5) * 100, y: 150)
            case 7, 8: // è‚˜
                let angle = Double.random(in: 90...140)
                return CGPoint(x: 200 + Double(index - 7) * 100, y: 200 + sin(angle * .pi / 180) * 50)
            case 9, 10: // æ‰‹é¦–
                return CGPoint(x: 200 + Double(index - 9) * 100, y: 250 + Double.random(in: -30...30))
            default:
                return CGPoint(x: Double.random(in: 100...300), y: Double.random(in: 100...400))
            }
        }
        
        let confidences = (0..<17).map { _ in Float.random(in: 0.7...1.0) }
        let mockKeypoints = PoseKeypoints(points: points, confidence: confidences)
        
        // Published ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’æ›´æ–°
        Task { @MainActor in
            self.lastDetectedPose = mockKeypoints
        }
        
        return mockKeypoints
    }
    
    private func generateMockFormClassification() -> FormClassification {
        let classifications: [FormClassification] = [.normal, .elbowError, .tooFast, .ready]
        return classifications.randomElement() ?? .normal
    }
    
    // MARK: - Performance Monitoring
    
    func updatePerformanceMetrics(inferenceTime: TimeInterval) {
        Task { @MainActor in
            self.lastInferenceTime = inferenceTime
        }
    }
}

// MARK: - Extensions

extension MLModelManager {
    
    /// ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹æƒ…å ±ã‚’å–å¾—
    var modelStatus: String {
        if isModelLoaded {
            return "âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†"
        } else if loadingError != nil {
            return "âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼"
        } else {
            return "ğŸ”„ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­..."
        }
    }
    
    /// ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    var debugInfo: String {
        return """
        MLModelManager Debug Info:
        - Pose Model: \(poseModel != nil ? "Loaded" : "Mock Mode")
        - Form Model: \(formModel != nil ? "Loaded" : "Mock Mode")
        - Last Inference: \(String(format: "%.1fms", lastInferenceTime * 1000))
        - Status: \(modelStatus)
        """
    }
}